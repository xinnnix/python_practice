{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f76f3de-ee2e-4cdc-a95c-5927a036d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4061ad-3404-4569-a3a3-b726c886dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load('celeb_a:2.0.1', split=['train','test'], shuffle_files=True,\n",
    "                                          with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02216759-d3a3-4ca1-94e3-6e3eb13737d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def preprocess(sample):\n",
    "    image = sample['image']\n",
    "    image = tf.image.resize(image, [112,112])\n",
    "    image = tf.cast(image, tf.float32)/255.\n",
    "    return image, image\n",
    "\n",
    "ds_train = ds_train.map(preprocess)\n",
    "ds_train = ds_train.shuffle(batch_size*4)\n",
    "ds_train = ds_train.batch(batch_size).prefetch(batch_size)\n",
    "\n",
    "ds_test = ds_test.map(preprocess).batch(batch_size).prefetch(batch_size)\n",
    "\n",
    "train_num = ds_info.splits['train'].num_examples\n",
    "test_num = ds_info.splits['test'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e2a5b62-4be6-472d-ba21-b069c2d90f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        means, logvar = inputs\n",
    "        epsilon = tf.random.normal(shape=tf.shape(means), mean=0., stddev=1.)\n",
    "        samples = means + tf.exp(0.5*logvar)*epsilon\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18f8e94-f5cb-47f9-8756-5f5ecb3eccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConvBlock(layers.Layer):\n",
    "    count = 0\n",
    "    def __init__(self, filters, kernel_size=(3,3), strides=1, padding='same'):\n",
    "        super(DownConvBlock, self).__init__(name=f'DownConvBlock_{DownConvBlock.count}')\n",
    "        DownConvBlock.count += 1\n",
    "        self.forward = keras.Sequential([layers.Conv2D(filters, kernel_size, strides, padding)])\n",
    "        self.forward.add(layers.BatchNormalization())\n",
    "        self.forward.add(layers.LeakyReLU(0.2))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e451fed4-a590-4f9f-b427-2888b9d21b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConvBlock(layers.Layer):\n",
    "    count = 0\n",
    "    def __init__(self, filters, kernel_size=(3,3), strides=1, padding='same'):\n",
    "        super(UpConvBlock, self).__init__(name=f'UpConvBlock_{UpConvBlock.count}')\n",
    "        UpConvBlock.count += 1\n",
    "        self.forward = keras.Sequential([layers.Conv2D(filters, kernel_size, strides, padding)])\n",
    "        self.forward.add(layers.LeakyReLU(0.2))\n",
    "        self.forward.add(layers.UpSampling2D((2,2)))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ed37a23-0e86-4c26-96c3-3a1fa3e5de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, z_dim, name='encoder'):\n",
    "        super(Encoder, self).__init__(name.name)\n",
    "        self.features_extract = keras.Sequential([\n",
    "            DownConvBlock(filters=32, kernel_size=(3,3), strides=2),\n",
    "            DownConvBlock(filters=32, kernel_size=(3,3), strides=2),\n",
    "            DownConvBlock(filters=64, kernel_size=(3,3), strides=2),\n",
    "            DownConvBlock(filters=64, kernel_size=(3,3), strides=2),\n",
    "            layers.Flatten()])\n",
    "        self.dense_mean = layers.Dense(z_dim, name='mean')\n",
    "        self.dense_logvar = layers.Dense(z_dim, name='logvar')\n",
    "        self.sampler = GaussianSampling()\n",
    "    def call(self, inputs):\n",
    "        x = self.features_extract(inputs)\n",
    "        mean = self.dense_mean(x)\n",
    "        logvar = self.dense_logvar(x)\n",
    "        z = self.sampler([mean, logvar])\n",
    "        return z, mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e786649-d090-4283-aa96-1c8a7e7993d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, z_dim, name='decoder'):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "        self.forward = keras.Sequential([\n",
    "            layers.Dense(7*7*64, activation='relu'),\n",
    "            layers.Reshape((7,7,64)),\n",
    "            UpConvBlock(filters=64, kernel_size=(3,3)),\n",
    "            UpConvBlock(filters=64, kernel_size=(3,3)),\n",
    "            UpConvBlock(filters=32, kernel_size=(3,3)),\n",
    "            UpConvBlock(filters=32, kernel_size=(3,3)),\n",
    "            layers.Conv2D(filters=3, kernel_size=(3,3), strides=1, padding='same', activation='sigmoid'),\n",
    "        ])\n",
    "    def call(self, inputs):\n",
    "        return self.forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1cf48d1-2163-4d49-87f4-78a758b5e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, z_dim, name='VAE'):\n",
    "        super(VAE, self).__init__(name=name)\n",
    "        self.encoder = Encoder(z_dim)\n",
    "        self.decoder = Decoder(z_dim)\n",
    "        self.mean = None\n",
    "        self.logvar = None\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        z, self.mean, self.logvar = self.encoder(inputs)\n",
    "        out = self.decoder(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61d9f3c4-d5f2-4d8f-9d5f-6e600c5fd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_kl_loss(y_true, y_pred):\n",
    "    kl_loss = - 0.5 * tf.reduce_mean(1 + vae.logvar - tf.square(vae.mean) - tf.exp(vae.logvar))\n",
    "    return kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d489126-0e65-45b1-9097-6c907f783040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_rc_loss(y_true, y_pred):\n",
    "    rc_loss = tf.keras.losses.MSE(y_true, y_pred)\n",
    "    return rc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f97b691-3391-4529-bf35-4ccf2b969fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    kl_loss = vae_kl_loss(y_true, y_pred)\n",
    "    rc_loss = vae_rc_loss(y_true, y_pred)\n",
    "    kl_weight_const = 0.01\n",
    "    return kl_weight_const * kl_loss + rc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f6987-1b37-45c2-880e-7fb0a41080f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
