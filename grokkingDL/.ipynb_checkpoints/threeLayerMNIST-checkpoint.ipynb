{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42f62fe-72be-40a0-89a3-91c1bd4ca3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94225f00-1eac-4033-88c4-f4daa2b39b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888ddb4b-b941-4803-97c5-2f0c089e4540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 11s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6529686-34ae-4d59-89d0-8dc95d4f6e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d30dc7a0-a7a3-4b9f-a54d-ab95df1e84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46c96f6c-c77b-4b53-8c7b-4638de649dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = x_test.reshape(len(x_test),28*28)/255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73186af2-b810-4b82-ae40-00efd0fe1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ca9df6-f6ae-43b7-9826-bffc078720c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = lambda x:(x>=0)*x\n",
    "relu2deriv = lambda x: x>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b6c720-b900-4a76-a69b-66c6a1582b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "iterations = 350\n",
    "hidden_size = 40\n",
    "pixels_per_image = 784\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b93aee-88a7-404a-8900-890dde79b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0_1 = 0.2 * np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e469b56-d419-4262-8bed-04622b199d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:349 Error:0.108 Correct:1.099"
     ]
    }
   ],
   "source": [
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        error += np.sum((labels[i:i+1] - layer_2)**2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(labels[i:i+1]))\n",
    "        \n",
    "        layer_2_delta = (layer_2 - labels[i:i+1])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    sys.stdout.write('\\r'+' I:'+str(j)+' Error:'+str(error/float(len(images)))[0:5]+' Correct:'+str(correct_cnt/float(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41719380-bcaa-4c79-b8a7-bb0ed1bf58c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err: 0.653 Test-Acc: 0.7073\n"
     ]
    }
   ],
   "source": [
    "if (j%10 == 0 or j == iterations -1):\n",
    "    error, correct_cnt = 0.0, 0\n",
    "    \n",
    "    for i in range(len(test_images)):\n",
    "        \n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        error += (np.sum((layer_2 - test_labels[i:i+1]) **2))\n",
    "        correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "    sys.stdout.write(' Test-Err: ' +str(error/float(len(test_images)))[0:5] + \n",
    "                     ' Test-Acc: ' + str(correct_cnt/float(len(test_images))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecac9f19-9db7-4214-ab74-4ec3a460659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0Test-Acc0.1422Train-Acc0.104\n",
      "I:10Test-Acc0.6065Train-Acc0.564\n",
      "I:20Test-Acc0.5836Train-Acc0.6\n",
      "I:30Test-Acc0.5389Train-Acc0.561\n",
      "I:40Test-Acc0.5259Train-Acc0.568\n",
      "I:50Test-Acc0.5632Train-Acc0.585\n",
      "I:60Test-Acc0.6149Train-Acc0.642\n",
      "I:70Test-Acc0.6711Train-Acc0.688\n",
      "I:80Test-Acc0.7189Train-Acc0.731\n",
      "I:90Test-Acc0.7606Train-Acc0.778\n",
      "I:100Test-Acc0.7831Train-Acc0.818\n",
      "I:110Test-Acc0.802Train-Acc0.839\n",
      "I:120Test-Acc0.8112Train-Acc0.853\n",
      "I:130Test-Acc0.8177Train-Acc0.873\n",
      "I:140Test-Acc0.8229Train-Acc0.871\n",
      "I:150Test-Acc0.8264Train-Acc0.875\n",
      "I:160Test-Acc0.8324Train-Acc0.882\n",
      "I:170Test-Acc0.8355Train-Acc0.897\n",
      "I:180Test-Acc0.8395Train-Acc0.899\n",
      "I:190Test-Acc0.8433Train-Acc0.898\n",
      "I:200Test-Acc0.8466Train-Acc0.912\n",
      "I:210Test-Acc0.8494Train-Acc0.906\n",
      "I:220Test-Acc0.8506Train-Acc0.917\n",
      "I:230Test-Acc0.8525Train-Acc0.917\n",
      "I:240Test-Acc0.8542Train-Acc0.918\n",
      "I:250Test-Acc0.856Train-Acc0.926\n",
      "I:260Test-Acc0.8573Train-Acc0.929\n",
      "I:270Test-Acc0.8584Train-Acc0.933\n",
      "I:280Test-Acc0.8589Train-Acc0.933\n",
      "I:290Test-Acc0.8592Train-Acc0.928"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28)/255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,j in enumerate(labels):\n",
    "    one_hot_labels[i][j] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28)/255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "\n",
    "for i,j in enumerate(y_test):\n",
    "    test_labels[i][j] = 1\n",
    "    \n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh2deriv(output):\n",
    "    return 1-(output**2)\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp/np.sum(temp, axis=1, keepdims=True)\n",
    "\n",
    "alpha, iterations, hidden_size = 2,300,100\n",
    "\n",
    "pixels_per_image, num_labels = 784, 10\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "weights_0_1 = 0.02*np.random.random((pixels_per_image,hidden_size)) - 0.01\n",
    "weights_1_2 = 0.02*np.random.random((hidden_size, num_labels)) - 0.01\n",
    "\n",
    "for j in range(iterations):\n",
    "    correct_cnt = 0\n",
    "    for i in range(int(len(images)/batch_size)):\n",
    "        batch_start, batch_end = i*batch_size,(i+1)*batch_size\n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_1 = tanh(np.dot(layer_0, weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask*2\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
    "        \n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
    "        layer_2_delta = (layer_2 - labels[batch_start:batch_end]) / (batch_size * layer_2.shape[0])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    test_correct_cnt = 0\n",
    "    \n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = tanh(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
    "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "        \n",
    "    if (j%10==0):\n",
    "        sys.stdout.write('\\n'+'I:'+str(j)+\n",
    "                         'Test-Acc' + str(test_correct_cnt/float(len(test_images)))+\n",
    "                         'Train-Acc' + str(correct_cnt/float(len(images))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
